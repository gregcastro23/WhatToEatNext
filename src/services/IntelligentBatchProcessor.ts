/**
 * Intelligent Batch Processing System - Phase 3.10 Implementation
 *
 * Advanced batch processing system for automated error fixing and optimization
 * Uses machine learning-inspired algorithms for intelligent batching and scheduling
 *
 * Features:
 * - Intelligent error grouping and batching
 * - Adaptive batch sizing based on success rates
 * - Parallel processing with resource management
 * - Predictive scheduling and optimization
 * - Safety mechanisms and rollback capabilities
 * - Real-time performance monitoring
 * - Automated quality validation
 */

import { execSync } from 'child_process';
import { EventEmitter } from 'events';
import fs from 'fs';

import { log } from '@/services/LoggingService';

import { TypeScriptError, ErrorCategory } from './campaign/TypeScriptErrorAnalyzer';
import { ErrorPattern } from './ErrorTrackingEnterpriseSystem';

// ========== BATCH PROCESSING INTERFACES ==========;

export interface BatchJob {
  jobId: string;
  batchId: string;
  errors: TypeScriptError[];
  pattern: ErrorPattern;
  status: 'pending' | 'processing' | 'completed' | 'failed' | 'cancelled';
  priority: number;
  estimatedTime: number;
  actualTime: number;
  retryCount: number;
  maxRetries: number;
  createdAt: Date;
  startedAt?: Date;
  completedAt?: Date;
  result?: BatchJobResult;
}

export interface BatchJobResult {
  success: boolean;
  errorsFixed: number;
  errorsRemaining: number;
  filesModified: string[];
  buildValidationPassed: boolean;
  testValidationPassed: boolean;
  safetyScore: number;
  warnings: string[];
  errors: string[];
  executionTime: number;
  rollbackData?: RollbackData;
}

export interface RollbackData {
  rollbackId: string;
  jobId: string;
  modifiedFiles: Array<{
    filePath: string;
    originalContent: string;
    modifiedContent: string;
  }>;
  gitStashRef?: string;
  timestamp: Date;
}

export interface BatchQueue {
  queueId: string;
  jobs: BatchJob[];
  concurrency: number;
  maxConcurrency: number;
  processing: Set<string>;
  completed: BatchJob[];
  failed: BatchJob[];
  totalJobs: number;
  totalCompleted: number;
  totalFailed: number;
  averageExecutionTime: number;
  successRate: number;
  createdAt: Date;
  status: 'idle' | 'processing' | 'paused' | 'completed';
}

export interface BatchOptimization {
  optimizationId: string;
  strategy: 'size' | 'pattern' | 'priority' | 'resource' | 'hybrid';
  parameters: Record<string, number>;
  effectiveness: number;
  successRate: number;
  averageTime: number;
  lastUsed: Date;
  adaptations: number;
}

export interface BatchSchedule {
  scheduleId: string;
  name: string;
  enabled: boolean;
  cronExpression: string;
  batchSize: number;
  concurrency: number;
  filters: {
    categories: ErrorCategory[];
    minPriority: number;
    maxRetries: number;
    patterns: string[];
  };
  optimization: BatchOptimization;
  lastRun?: Date;
  nextRun?: Date;
  totalRuns: number;
  successfulRuns: number;
}

export interface BatchMetrics {
  totalJobs: number;
  completedJobs: number;
  failedJobs: number;
  activeJobs: number;
  averageExecutionTime: number;
  successRate: number;
  throughput: number; // jobs per minute
  resourceUtilization: {
    cpu: number;
    memory: number;
    disk: number;
  };
  errorReduction: {
    totalErrors: number;
    errorsFixed: number;
    reductionRate: number;
  };
  qualityMetrics: {
    buildStability: number;
    testStability: number;
    safetyScore: number;
  };
}

// ========== INTELLIGENT BATCH PROCESSOR ==========;

export class IntelligentBatchProcessor extends EventEmitter {
  private queues: Map<string, BatchQueue> = new Map();
  private optimizations: Map<string, BatchOptimization> = new Map();
  private schedules: Map<string, BatchSchedule> = new Map();
  private rollbackData: Map<string, RollbackData> = new Map();
  private isProcessing: boolean = false;
  private schedulerInterval: NodeJS.Timer | null = null;
  private metricsInterval: NodeJS.Timer | null = null;
  private readonly MAX_CONCURRENT_JOBS = 4;
  private readonly MAX_BATCH_SIZE = 50;
  private readonly MIN_BATCH_SIZE = 5;
  private readonly DEFAULT_TIMEOUT = 300000; // 5 minutes
  private readonly SAFETY_THRESHOLD = 0.7;
  private readonly QUALITY_THRESHOLD = 0.8;

  // Adaptive parameters
  private adaptiveParameters = {;
    learningRate: 0.1,
    explorationRate: 0.2,
    decayRate: 0.95,
    minSuccessRate: 0.6,
    maxRetries: 3,
    timeoutMultiplier: 1.5
  };

  // Performance tracking
  private performanceHistory: Array<{
    timestamp: Date;
    metrics: BatchMetrics;
    optimization: string;
    parameters: Record<string, number>;
  }> = [];

  constructor() {
    super();
    this.initializeOptimizations();
    this.loadPersistedData();
    this.setupEventHandlers();
  }

  // ========== INITIALIZATION ==========;

  private initializeOptimizations(): void {
    // Size-based optimization
    this.optimizations.set('size', {
      optimizationId: 'size_optimization',
      strategy: 'size',
      parameters: {
        minBatchSize: 10,
        maxBatchSize: 30,
        sizeGrowthRate: 0.1,
        sizeShrinkRate: 0.2
      },
      effectiveness: 0.75,
      successRate: 0.8,
      averageTime: 120,
      lastUsed: new Date(),
      adaptations: 0
    });

    // Pattern-based optimization
    this.optimizations.set('pattern', {
      optimizationId: 'pattern_optimization',
      strategy: 'pattern',
      parameters: {
        similarityThreshold: 0.8,
        patternWeight: 0.7,
        diversityBonus: 0.3
      },
      effectiveness: 0.85,
      successRate: 0.85,
      averageTime: 150,
      lastUsed: new Date(),
      adaptations: 0
    });

    // Priority-based optimization
    this.optimizations.set('priority', {
      optimizationId: 'priority_optimization',
      strategy: 'priority',
      parameters: {
        highPriorityThreshold: 20,
        mediumPriorityThreshold: 10,
        priorityWeight: 0.8
      },
      effectiveness: 0.8,
      successRate: 0.82,
      averageTime: 100,
      lastUsed: new Date(),
      adaptations: 0
    });

    // Resource-based optimization
    this.optimizations.set('resource', {
      optimizationId: 'resource_optimization',
      strategy: 'resource',
      parameters: {
        cpuThreshold: 70,
        memoryThreshold: 80,
        diskThreshold: 90,
        resourceWeight: 0.6
      },
      effectiveness: 0.7,
      successRate: 0.75,
      averageTime: 180,
      lastUsed: new Date(),
      adaptations: 0
    });

    // Hybrid optimization
    this.optimizations.set('hybrid', {
      optimizationId: 'hybrid_optimization',
      strategy: 'hybrid',
      parameters: {
        sizeWeight: 0.3,
        patternWeight: 0.3,
        priorityWeight: 0.2,
        resourceWeight: 0.2
      },
      effectiveness: 0.9,
      successRate: 0.88,
      averageTime: 130,
      lastUsed: new Date(),
      adaptations: 0
    });
  }

  // ========== BATCH CREATION ==========;

  /**
   * Create intelligent batches from error patterns
   */
  async createIntelligentBatches(
    errors: TypeScriptError[],
    patterns: ErrorPattern[],
    optimizationStrategy: string = 'hybrid',;
  ): Promise<BatchJob[]> {
    log.info(`üß† Creating intelligent batches using ${optimizationStrategy} strategy...`);

    const optimization = this.optimizations.get(optimizationStrategy);
    if (!optimization) {
      throw new Error(`Unknown optimization strategy: ${optimizationStrategy}`);
    }

    const batches: BatchJob[] = [];
    const processedErrors = new Set<string>();

    // Group errors by optimization strategy
    const errorGroups = this.groupErrors(errors, patterns, optimization);

    // Create batches from groups
    for (const [groupKey, groupErrors] of errorGroups) {
      const batchSize = this.calculateOptimalBatchSize(;
        groupErrors,
        optimization,
        this.getResourceUtilization(),
      );

      // Split group into batches
      const chunks = this.chunkArray(groupErrors, batchSize);

      for (const chunk of chunks) {
        const pattern = this.findDominantPattern(chunk, patterns);
        if (pattern) {
          const batch = this.createBatchJob(chunk, pattern, optimization);
          batches.push(batch);

          // Mark errors as processed
          chunk.forEach(error => processedErrors.add(this.getErrorId(error)));
        }
      }
    }

    // Create batches for remaining errors
    const remainingErrors = errors.filter(error => !processedErrors.has(this.getErrorId(error)));
    if (remainingErrors.length > 0) {
      const chunks = this.chunkArray(remainingErrors, this.MIN_BATCH_SIZE);
      for (const chunk of chunks) {
        const pattern = this.createGenericPattern(chunk);
        const batch = this.createBatchJob(chunk, pattern, optimization);
        batches.push(batch);
      }
    }

    log.info(`‚úÖ Created ${batches.length} intelligent batches`);
    return batches;
  }

  /**
   * Group errors by optimization strategy
   */
  private groupErrors(
    errors: TypeScriptError[],
    patterns: ErrorPattern[],
    optimization: BatchOptimization,
  ): Map<string, TypeScriptError[]> {
    const groups = new Map<string, TypeScriptError[]>();

    switch (optimization.strategy) {
      case 'size':
        return this.groupBySize(errors, optimization);
      case 'pattern':
        return this.groupByPattern(errors, patterns, optimization);
      case 'priority':
        return this.groupByPriority(errors, optimization);
      case 'resource':
        return this.groupByResource(errors, optimization);
      case 'hybrid':
        return this.groupByHybrid(errors, patterns, optimization);
      default:
        groups.set('default', errors);
        return groups;
    }
  }

  /**
   * Group errors by size constraints
   */
  private groupBySize(
    errors: TypeScriptError[],
    optimization: BatchOptimization,
  ): Map<string, TypeScriptError[]> {
    const groups = new Map<string, TypeScriptError[]>();
    const batchSize = optimization.parameters.maxBatchSize;

    for (let i = 0; i < errors.length; i += batchSize) {
      const groupKey = `size_group_${Math.floor(i / batchSize)}`;
      groups.set(groupKey, errors.slice(i, i + batchSize));
    }

    return groups;
  }

  /**
   * Group errors by pattern similarity
   */
  private groupByPattern(
    errors: TypeScriptError[],
    patterns: ErrorPattern[],
    optimization: BatchOptimization,
  ): Map<string, TypeScriptError[]> {
    const groups = new Map<string, TypeScriptError[]>();
    const threshold = optimization.parameters.similarityThreshold;

    for (const error of errors) {
      let assigned = false;

      // Find similar group
      for (const [groupKey, groupErrors] of groups) {
        if (groupErrors.length > 0) {
          const similarity = this.calculateErrorSimilarity(error, groupErrors[0]);
          if (similarity >= threshold) {
            groupErrors.push(error);
            assigned = true;
            break;
          }
        }
      }

      // Create new group if no similar group found
      if (!assigned) {
        const groupKey = `pattern_group_${error.code}_${groups.size}`;
        groups.set(groupKey, [error]);
      }
    }

    return groups;
  }

  /**
   * Group errors by priority
   */
  private groupByPriority(
    errors: TypeScriptError[],
    optimization: BatchOptimization,
  ): Map<string, TypeScriptError[]> {
    const groups = new Map<string, TypeScriptError[]>();
    const highThreshold = optimization.parameters.highPriorityThreshold;
    const mediumThreshold = optimization.parameters.mediumPriorityThreshold;

    groups.set(
      'high_priority',
      errors.filter(e => e.priority >= highThreshold),;
    );
    groups.set(
      'medium_priority',
      errors.filter(e => e.priority >= mediumThreshold && e.priority < highThreshold),;
    );
    groups.set(
      'low_priority',
      errors.filter(e => e.priority < mediumThreshold),;
    );

    // Remove empty groups
    for (const [key, value] of groups) {
      if (value.length === 0) {;
        groups.delete(key);
      }
    }

    return groups;
  }

  /**
   * Group errors by resource constraints
   */
  private groupByResource(
    errors: TypeScriptError[],
    optimization: BatchOptimization,
  ): Map<string, TypeScriptError[]> {
    const groups = new Map<string, TypeScriptError[]>();
    const resourceUtil = this.getResourceUtilization();

    // Adjust batch size based on resource utilization
    const baseBatchSize = 20;
    const resourceFactor = 1 - (resourceUtil.cpu + resourceUtil.memory + resourceUtil.disk) / 300;
    const adjustedBatchSize = Math.max(5, Math.round(baseBatchSize * resourceFactor));

    for (let i = 0; i < errors.length; i += adjustedBatchSize) {
      const groupKey = `resource_group_${Math.floor(i / adjustedBatchSize)}`;
      groups.set(groupKey, errors.slice(i, i + adjustedBatchSize));
    }

    return groups;
  }

  /**
   * Group errors using hybrid strategy
   */
  private groupByHybrid(
    errors: TypeScriptError[],
    patterns: ErrorPattern[],
    optimization: BatchOptimization,
  ): Map<string, TypeScriptError[]> {
    const groups = new Map<string, TypeScriptError[]>();
    const weights = optimization.parameters;

    // Sort errors by hybrid score
    const scoredErrors = errors;
      .map(error => ({;
        error,
        score: this.calculateHybridScore(error, weights)
      }))
      .sort((a, b) => b.score - a.score);

    // Group by score ranges
    const scoreRanges = [;
      { min: 0.8, max: 1.0, key: 'high_score' },
      { min: 0.6, max: 0.8, key: 'medium_score' },
      { min: 0.4, max: 0.6, key: 'low_score' },
      { min: 0.0, max: 0.4, key: 'very_low_score' }
    ];

    for (const range of scoreRanges) {
      const rangeErrors = scoredErrors;
        .filter(item => item.score >= range.min && item.score < range.max);
        .map(item => item.error);

      if (rangeErrors.length > 0) {
        groups.set(range.key, rangeErrors);
      }
    }

    return groups;
  }

  /**
   * Calculate hybrid score for error
   */
  private calculateHybridScore(error: TypeScriptError, weights: Record<string, number>): number {
    const priorityScore = error.priority / 30; // Normalize to 0-1
    const patternScore = this.getPatternScore(error);
    const complexityScore = this.getComplexityScore(error);
    const resourceScore = this.getResourceScore();

    return (
      priorityScore * weights.priorityWeight +
      patternScore * weights.patternWeight +
      complexityScore * weights.sizeWeight +
      resourceScore * weights.resourceWeight
    );
  }

  /**
   * Get pattern score for error
   */
  private getPatternScore(error: TypeScriptError): number {
    // Simple pattern scoring based on error code
    const patternScores: Record<string, number> = {
      TS2352: 0.9,
      TS2304: 0.85,
      TS2345: 0.8,
      TS2362: 0.75,
      TS2322: 0.7
    };

    return patternScores[error.code] || 0.5;
  }

  /**
   * Get complexity score for error
   */
  private getComplexityScore(error: TypeScriptError): number {
    const messageLength = error.message.length;
    const pathDepth = error.filePath.split('/').length;

    // Lower complexity = higher score;
    const lengthScore = Math.max(0, 1 - messageLength / 200);
    const depthScore = Math.max(0, 1 - pathDepth / 10);

    return (lengthScore + depthScore) / 2;
  }

  /**
   * Get resource score
   */
  private getResourceScore(): number {
    const resourceUtil = this.getResourceUtilization();
    const avgUtil = (resourceUtil.cpu + resourceUtil.memory + resourceUtil.disk) / 3;

    return Math.max(0, 1 - avgUtil / 100);
  }

  /**
   * Calculate optimal batch size
   */
  private calculateOptimalBatchSize(
    errors: TypeScriptError[],
    optimization: BatchOptimization,
    resourceUtil: { cpu: number; memory: number; disk: number },
  ): number {
    const baseSize = optimization.parameters.maxBatchSize || 20;

    // Adjust based on resource utilization
    const avgUtil = (resourceUtil.cpu + resourceUtil.memory + resourceUtil.disk) / 3;
    const resourceFactor = Math.max(0.3, 1 - avgUtil / 100);

    // Adjust based on error complexity
    const avgComplexity =
      errors.reduce((sum, e) => sum + this.getComplexityScore(e), 0) / errors.length;
    const complexityFactor = Math.max(0.5, avgComplexity);

    // Adjust based on success rate
    const successRate = optimization.successRate;
    const successFactor = Math.max(0.6, successRate);

    const adjustedSize = Math.round(baseSize * resourceFactor * complexityFactor * successFactor);

    return Math.max(this.MIN_BATCH_SIZE, Math.min(this.MAX_BATCH_SIZE, adjustedSize));
  }

  /**
   * Create batch job
   */
  private createBatchJob(
    errors: TypeScriptError[],
    pattern: ErrorPattern,
    optimization: BatchOptimization,
  ): BatchJob {
    const jobId = `job_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const batchId = `batch_${pattern.errorCode}_${Date.now()}`;

    return {
      jobId,
      batchId,
      errors,
      pattern,
      status: 'pending',
      priority: this.calculateJobPriority(errors, pattern),
      estimatedTime: this.estimateJobTime(errors, pattern, optimization),
      actualTime: 0,
      retryCount: 0,
      maxRetries: this.adaptiveParameters.maxRetries,
      createdAt: new Date()
    };
  }

  /**
   * Calculate job priority
   */
  private calculateJobPriority(errors: TypeScriptError[], pattern: ErrorPattern): number {
    const avgPriority = errors.reduce((sum, e) => sum + e.priority, 0) / errors.length;
    const patternBonus = ((pattern as any)?.frequency || 0) * 0.2;
    const automationBonus = pattern.automationPotential * 5;

    return Math.round(avgPriority + patternBonus + automationBonus);
  }

  /**
   * Estimate job execution time
   */
  private estimateJobTime(
    errors: TypeScriptError[],
    pattern: ErrorPattern,
    optimization: BatchOptimization,
  ): number {
    const baseTime = pattern.averageFixTime * 1000; // Convert to ms
    const errorCount = errors.length;
    const complexityFactor = this.getAverageComplexity(errors);

    return Math.round(baseTime * errorCount * complexityFactor * 1.2); // Add 20% buffer
  }

  /**
   * Get average complexity of errors
   */
  private getAverageComplexity(errors: TypeScriptError[]): number {
    return errors.reduce((sum, e) => sum + this.getComplexityScore(e), 0) / errors.length;
  }

  // ========== BATCH PROCESSING ==========;

  /**
   * Process batch queue
   */
  async processBatchQueue(queueId: string): Promise<void> {
    const queue = this.queues.get(queueId);
    if (!queue) {
      throw new Error(`Queue ${queueId} not found`);
    }

    if (queue.status !== 'idle') {
      log.info(`‚ö†Ô∏è  Queue ${queueId} is already ${queue.status}`);
      return;
    }

    queue.status = 'processing';
    this.isProcessing = true;

    log.info(`üöÄ Processing batch queue ${queueId} with ${queue.jobs.length} jobs`);

    try {
      while (queue.jobs.length > 0 && queue.processing.size < queue.maxConcurrency) {
        const job = this.selectNextJob(queue);
        if (job) {
          await this.processJob(job, queue);
        } else {
          break;
        }
      }

      // Wait for all jobs to complete
      while (queue.processing.size > 0) {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }

      queue.status = 'completed';
      log.info(`‚úÖ Batch queue ${queueId} completed successfully`);
    } catch (error) {
      console.error(`‚ùå Error processing batch queue ${queueId}:`, error);
      queue.status = 'idle';
    } finally {
      this.isProcessing = false;
    }
  }

  /**
   * Select next job from queue
   */
  private selectNextJob(queue: BatchQueue): BatchJob | null {
    const availableJobs = queue.jobs.filter(job => job.status === 'pending');
    if (availableJobs.length === 0) return null;

    // Sort by priority (highest first)
    availableJobs.sort((a, b) => b.priority - a.priority);

    return availableJobs[0];
  }

  /**
   * Process individual job
   */
  private async processJob(job: BatchJob, queue: BatchQueue): Promise<void> {
    job.status = 'processing';
    job.startedAt = new Date();
    queue.processing.add(job.jobId);

    log.info(`üîÑ Processing job ${job.jobId} (${job.errors.length} errors)`);

    try {
      // Create rollback point
      await this.createRollbackPoint(job);

      // Execute job
      const result = await this.executeJob(job);

      // Validate result
      const validationResult = await this.validateJobResult(job, result);

      if (validationResult.success) {
        job.status = 'completed';
        job.result = result;
        job.completedAt = new Date();
        job.actualTime = job.completedAt.getTime() - job.startedAt.getTime();

        queue.completed.push(job);
        queue.totalCompleted++;

        log.info(`‚úÖ Job ${job.jobId} completed successfully`);
        this.emit('job-completed', job);
      } else {
        await this.handleJobFailure(
          job,
          queue,
          new Error(validationResult.error || 'Validation failed'),
        );
      }

      // Update optimization based on result
      this.updateOptimization(job, result);
    } catch (error) {
      await this.handleJobFailure(job, queue, error as Error);
    } finally {
      queue.processing.delete(job.jobId);

      // Remove job from pending queue
      const jobIndex = queue.jobs.findIndex(j => j.jobId === job.jobId);
      if (jobIndex !== -1) {
        queue.jobs.splice(jobIndex, 1);
      }
    }
  }

  /**
   * Execute job
   */
  private async executeJob(job: BatchJob): Promise<BatchJobResult> {
    const startTime = Date.now();

    try {
      // Use the existing TypeScript error fixer
      const fixerCommand = this.buildFixerCommand(job);
      const output = execSync(fixerCommand, {;
        encoding: 'utf8',
        timeout: this.DEFAULT_TIMEOUT,
        stdio: 'pipe'
      });

      const result = this.parseFixerOutput(output);
      result.executionTime = Date.now() - startTime;

      return result;
    } catch (error) {
      throw new Error(
        `Job execution failed: ${error instanceof Error ? error.message : String(error)}`,
      );
    }
  }

  /**
   * Build fixer command for job
   */
  private buildFixerCommand(job: BatchJob): string {
    const maxFiles = Math.min(job.errors.length, 25); // Limit to prevent overflow
    const errorCodes = [...new Set(job.errors.map(e => e.code))].join(',');

    return `node scripts/typescript-fixes/fix-typescript-errors-enhanced-v3.js --max-files=${maxFiles} --auto-fix --error-codes=${errorCodes}`;
  }

  /**
   * Parse fixer output
   */
  private parseFixerOutput(output: string): BatchJobResult {
    const lines = output.split('\n');
    let errorsFixed = 0;
    let errorsRemaining = 0;
    let filesModified: string[] = [];
    let buildValidationPassed = true;
    const testValidationPassed = true;
    let safetyScore = 0.8;
    const warnings: string[] = [];
    const errors: string[] = [];

    for (const line of lines) {
      if (line.includes('errors fixed:')) {
        const match = line.match(/(\d+)\s+errors fixed/);
        if (match) errorsFixed = parseInt(match[1]);
      }

      if (line.includes('errors remaining:')) {
        const match = line.match(/(\d+)\s+errors remaining/);
        if (match) errorsRemaining = parseInt(match[1]);
      }

      if (line.includes('files modified:')) {
        const match = line.match(/files modified:\s*(.+)/);
        if (match) {
          filesModified = match[1];
            .split(',')
            .map(f => f.trim());
            .filter(f => f);
        }
      }

      if (line.includes('build validation:')) {
        buildValidationPassed = line.includes('passed');
      }

      if (line.includes('safety score:')) {
        const match = line.match(/safety score:\s*(\d+\.?\d*)/);
        if (match) safetyScore = parseFloat(match[1]);
      }

      if (line.includes('WARNING:')) {
        warnings.push(line.replace('WARNING:', '').trim());
      }

      if (line.includes('ERROR:')) {
        errors.push(line.replace('ERROR:', '').trim());
      }
    }

    return {
      success: errors.length === 0 && safetyScore >= this.SAFETY_THRESHOLD,;
      errorsFixed,
      errorsRemaining,
      filesModified,
      buildValidationPassed,
      testValidationPassed,
      safetyScore,
      warnings,
      errors,
      executionTime: 0, // Will be set by caller
    };
  }

  /**
   * Validate job result
   */
  private async validateJobResult(
    job: BatchJob,
    result: BatchJobResult,
  ): Promise<{ success: boolean; error?: string }> {
    // Check safety score
    if (result.safetyScore < this.SAFETY_THRESHOLD) {
      return {
        success: false,
        error: `Safety score ${result.safetyScore} below threshold ${this.SAFETY_THRESHOLD}`
      };
    }

    // Check build validation
    if (!result.buildValidationPassed) {
      return { success: false, error: 'Build validation failed' };
    }

    // Check for critical errors
    if (result.errors.length > 0) {
      return { success: false, error: `Critical errors: ${result.errors.join(', ')}` };
    }

    // Check if we actually fixed some errors
    if (result.errorsFixed === 0) {;
      return { success: false, error: 'No errors were fixed' };
    }

    return { success: true };
  }

  /**
   * Handle job failure
   */
  private async handleJobFailure(job: BatchJob, queue: BatchQueue, error: Error): Promise<void> {
    console.error(`‚ùå Job ${job.jobId} failed:`, error.message);

    job.retryCount++;

    if (job.retryCount <= job.maxRetries) {
      log.info(`üîÑ Retrying job ${job.jobId} (attempt ${job.retryCount}/${job.maxRetries})`);
      job.status = 'pending';
      job.startedAt = undefined;

      // Add back to queue with lower priority
      job.priority = Math.max(1, job.priority - 5);
      queue.jobs.unshift(job);
    } else {
      console.error(`üí• Job ${job.jobId} failed permanently after ${job.maxRetries} retries`);
      job.status = 'failed';
      job.completedAt = new Date();
      job.actualTime = job.completedAt.getTime() - (job.startedAt?.getTime() ?? 0);

      queue.failed.push(job);
      queue.totalFailed++;

      // Attempt rollback
      await this.rollbackJob(job);

      this.emit('job-failed', job, error);
    }
  }

  /**
   * Create rollback point
   */
  private async createRollbackPoint(job: BatchJob): Promise<RollbackData> {
    const rollbackId = `rollback_${job.jobId}_${Date.now()}`;

    try {
      // Create git stash for safety
      const stashRef = execSync('git stash push -m 'Batch job rollback point'', {;
        encoding: 'utf8',
        timeout: 30000
      }).trim();

      const rollbackData: RollbackData = {;
        rollbackId,
        jobId: job.jobId,
        modifiedFiles: [],
        gitStashRef: stashRef,
        timestamp: new Date()
      };

      this.rollbackData.set(rollbackId, rollbackData);
      return rollbackData;
    } catch (error) {
      console.warn('‚ö†Ô∏è  Failed to create git stash rollback point:', error);

      // Fallback to file-based rollback
      const rollbackData: RollbackData = {;
        rollbackId,
        jobId: job.jobId,
        modifiedFiles: [],
        timestamp: new Date()
      };

      this.rollbackData.set(rollbackId, rollbackData);
      return rollbackData;
    }
  }

  /**
   * Rollback job changes
   */
  private async rollbackJob(job: BatchJob): Promise<void> {
    const rollbackData = Array.from(this.rollbackData.values()).find(rd => rd.jobId === job.jobId);

    if (!rollbackData) {
      console.warn(`‚ö†Ô∏è  No rollback data found for job ${job.jobId}`);
      return;
    }

    try {
      if (rollbackData.gitStashRef) {
        // Use git stash for rollback
        execSync(`git stash pop ${rollbackData.gitStashRef}`, {
          encoding: 'utf8',
          timeout: 30000
        });
        log.info(`üîÑ Rolled back job ${job.jobId} using git stash`);
      } else {
        // Use file-based rollback
        for (const file of rollbackData.modifiedFiles) {
          fs.writeFileSync(file.filePath, file.originalContent);
        }
        log.info(`üîÑ Rolled back job ${job.jobId} using file restore`);
      }
    } catch (error) {
      console.error(`‚ùå Failed to rollback job ${job.jobId}:`, error);
    }
  }

  /**
   * Update optimization based on job result
   */
  private updateOptimization(job: BatchJob, result: BatchJobResult): void {
    // Find the optimization strategy used
    const optimizationStrategy = this.findOptimizationStrategy(job);
    const optimization = this.optimizations.get(optimizationStrategy);

    if (!optimization) return;

    // Update success rate
    const newSuccessRate = result.success ? 1 : 0;
    optimization.successRate =
      optimization.successRate * (1 - this.adaptiveParameters.learningRate) +;
      newSuccessRate * this.adaptiveParameters.learningRate;

    // Update average time
    optimization.averageTime =
      optimization.averageTime * (1 - this.adaptiveParameters.learningRate) +;
      result.executionTime * this.adaptiveParameters.learningRate;

    // Update effectiveness
    const effectiveness = (result.errorsFixed / job.errors.length) * result.safetyScore;
    optimization.effectiveness =
      optimization.effectiveness * (1 - this.adaptiveParameters.learningRate) +;
      effectiveness * this.adaptiveParameters.learningRate;

    // Increment adaptations
    optimization.adaptations++;
    optimization.lastUsed = new Date();

    // Adapt parameters based on performance
    this.adaptOptimizationParameters(optimization, result);

    log.info(
      `üìä Updated ${optimizationStrategy} optimization: ${(optimization.effectiveness * 100).toFixed(1)}% effectiveness`,
    );
  }

  /**
   * Find optimization strategy used for job
   */
  private findOptimizationStrategy(job: BatchJob): string {
    // Simple heuristic - could be improved with explicit tracking
    if (job.errors.length <= 10) return 'size';
    if (job.priority > 20) return 'priority';
    if (job.errors.every(e => e.code === job.errors[0].code)) return 'pattern';
    return 'hybrid';
  }

  /**
   * Adapt optimization parameters
   */
  private adaptOptimizationParameters(
    optimization: BatchOptimization,
    result: BatchJobResult,
  ): void {
    switch (optimization.strategy) {
      case 'size':
        if (result.success && result.errorsFixed > 0) {
          optimization.parameters.maxBatchSize += 1;
        } else if (!result.success) {
          optimization.parameters.maxBatchSize = Math.max(;
            5,
            optimization.parameters.maxBatchSize - 2,
          );
        }
        break;

      case 'pattern':
        if (result.success) {
          optimization.parameters.similarityThreshold -= 0.01;
        } else {
          optimization.parameters.similarityThreshold += 0.02;
        }
        optimization.parameters.similarityThreshold = Math.max(;
          0.5,
          Math.min(0.95, optimization.parameters.similarityThreshold),
        );
        break;

      case 'priority':
        if (result.success) {
          optimization.parameters.priorityWeight += 0.05;
        } else {
          optimization.parameters.priorityWeight -= 0.02;
        }
        optimization.parameters.priorityWeight = Math.max(;
          0.1,
          Math.min(1.0, optimization.parameters.priorityWeight),
        );
        break;

      case 'resource':
        const resourceUtil = this.getResourceUtilization();
        if (result.success && resourceUtil.cpu < 80) {
          optimization.parameters.cpuThreshold += 2;
        } else if (!result.success || resourceUtil.cpu > 90) {
          optimization.parameters.cpuThreshold -= 5;
        }
        optimization.parameters.cpuThreshold = Math.max(;
          50,
          Math.min(95, optimization.parameters.cpuThreshold),
        );
        break;

      case 'hybrid':
        // Adjust hybrid weights based on success
        if (result.success) {
          const bestStrategy = this.findBestStrategy();
          if (bestStrategy === 'pattern') {;
            optimization.parameters.patternWeight += 0.02;
          } else if (bestStrategy === 'priority') {;
            optimization.parameters.priorityWeight += 0.02;
          }
        }
        this.normalizeHybridWeights(optimization);
        break;
    }
  }

  /**
   * Find best performing strategy
   */
  private findBestStrategy(): string {
    let bestStrategy = 'hybrid';
    let bestScore = 0;

    for (const [strategy, optimization] of this.optimizations) {
      const score = optimization.effectiveness * optimization.successRate;
      if (score > bestScore) {
        bestScore = score;
        bestStrategy = strategy;
      }
    }

    return bestStrategy;
  }

  /**
   * Normalize hybrid weights
   */
  private normalizeHybridWeights(optimization: BatchOptimization): void {
    const totalWeight =
      optimization.parameters.sizeWeight +;
      optimization.parameters.patternWeight +
      optimization.parameters.priorityWeight +
      optimization.parameters.resourceWeight;

    if (totalWeight > 0) {
      optimization.parameters.sizeWeight /= totalWeight;
      optimization.parameters.patternWeight /= totalWeight;
      optimization.parameters.priorityWeight /= totalWeight;
      optimization.parameters.resourceWeight /= totalWeight;
    }
  }

  // ========== QUEUE MANAGEMENT ==========;

  /**
   * Create batch queue
   */
  createBatchQueue(
    queueId: string,
    jobs: BatchJob[],
    maxConcurrency: number = this.MAX_CONCURRENT_JOBS,;
  ): BatchQueue {
    const queue: BatchQueue = {;
      queueId,
      jobs: [...jobs],
      concurrency: 0,
      maxConcurrency,
      processing: new Set(),
      completed: [],
      failed: [],
      totalJobs: jobs.length,
      totalCompleted: 0,
      totalFailed: 0,
      averageExecutionTime: 0,
      successRate: 0,
      createdAt: new Date(),
      status: 'idle'
    };

    this.queues.set(queueId, queue);
    return queue;
  }

  /**
   * Get queue status
   */
  getQueueStatus(queueId: string): BatchQueue | null {
    return this.queues.get(queueId) || null;
  }

  /**
   * Get all queues
   */
  getAllQueues(): BatchQueue[] {
    return Array.from(this.queues.values());
  }

  /**
   * Cancel queue
   */
  cancelQueue(queueId: string): void {
    const queue = this.queues.get(queueId);
    if (queue) {
      queue.status = 'idle';
      queue.jobs.forEach(job => {;
        if (job.status === 'pending') {;
          job.status = 'cancelled';
        }
      });
    }
  }

  /**
   * Clear completed queues
   */
  clearCompletedQueues(): void {
    for (const [queueId, queue] of this.queues) {
      if (queue.status === 'completed') {;
        this.queues.delete(queueId);
      }
    }
  }

  // ========== UTILITY METHODS ==========;

  private chunkArray<T>(array: T[], chunkSize: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += chunkSize) {
      chunks.push(array.slice(i, i + chunkSize));
    }
    return chunks;
  }

  private getErrorId(error: TypeScriptError): string {
    return `${error.filePath}:${error.line}:${error.column}:${error.code}`;
  }

  private calculateErrorSimilarity(error1: TypeScriptError, error2: TypeScriptError): number {
    if (error1.code !== error2.code) return 0;

    const categoryMatch = error1.category === error2.category ? 0.3 : 0;
    const severityMatch = error1.severity === error2.severity ? 0.2 : 0;
    const fileMatch =
      error1.filePath.split('/').pop() === error2.filePath.split('/').pop() ? 0.2 : 0;
    const messageMatch = this.calculateMessageSimilarity(error1.message, error2.message) * 0.3;

    return categoryMatch + severityMatch + fileMatch + messageMatch;
  }

  private calculateMessageSimilarity(msg1: string, msg2: string): number {
    const words1 = msg1.toLowerCase().split(/\s+/);
    const words2 = msg2.toLowerCase().split(/\s+/);

    const intersection = words1.filter(word => words2.includes(word));
    const union = [...new Set([...words1, ...words2])];

    return intersection.length / union.length;
  }

  private findDominantPattern(
    errors: TypeScriptError[],
    patterns: ErrorPattern[],
  ): ErrorPattern | null {
    if (errors.length === 0) return null;

    const errorCode = errors[0].code;
    return patterns.find(p => p.errorCode === errorCode) || null;
  }

  private createGenericPattern(errors: TypeScriptError[]): ErrorPattern {
    const errorCode = errors[0].code;

    return {
      patternId: `generic_${errorCode}_${Date.now()}`,
      errorCode,
      frequency: errors.length,
      successRate: 0.7,
      averageFixTime: 3.0,
      complexity: 'medium',
      automationPotential: 0.6,
      lastSeen: new Date()
    };
  }

  private getResourceUtilization(): { cpu: number; memory: number; disk: number } {
    try {
      // Simple resource monitoring
      const memoryUsage = process.memoryUsage();
      const memoryPercent = (memoryUsage.heapUsed / memoryUsage.heapTotal) * 100;

      return {
        cpu: Math.random() * 20 + 10, // Mock CPU usage
        memory: Math.min(100, memoryPercent),
        disk: Math.random() * 30 + 20, // Mock disk usage
      };
    } catch (error) {
      return { cpu: 20, memory: 30, disk: 25 };
    }
  }

  // ========== EVENT HANDLERS ==========;

  private setupEventHandlers(): void {
    this.on('job-completed', (job: BatchJob) => {
      log.info(`‚úÖ Job ${job.jobId} completed: ${job.result?.errorsFixed} errors fixed`);
    });

    this.on('job-failed', (job: BatchJob, error: Error) => {
      console.error(`‚ùå Job ${job.jobId} failed: ${error.message}`);
    });
  }

  // ========== DATA PERSISTENCE ==========;

  private async persistData(): Promise<void> {
    try {
      const data = {;
        queues: Array.from(this.queues.entries()),
        optimizations: Array.from(this.optimizations.entries()),
        schedules: Array.from(this.schedules.entries()),
        rollbackData: Array.from(this.rollbackData.entries())
      };

      await fs.promises.writeFile(
        '.intelligent-batch-processor.json',
        JSON.stringify(data, null, 2),
      );
    } catch (error) {
      console.error('‚ùå Failed to persist batch processor data:', error);
    }
  }

  private loadPersistedData(): void {
    try {
      if (fs.existsSync('.intelligent-batch-processor.json')) {
        const data = JSON.parse(fs.readFileSync('.intelligent-batch-processor.json', 'utf8'));

        this.queues = new Map(data.queues || []);
        this.optimizations = new Map(data.optimizations || []);
        this.schedules = new Map(data.schedules || []);
        this.rollbackData = new Map(data.rollbackData || []);
      }
    } catch (error) {
      console.error('‚ö†Ô∏è  Failed to load persisted data:', error);
    }
  }

  // ========== PUBLIC API ==========;

  getMetrics(): BatchMetrics {
    const allQueues = Array.from(this.queues.values());
    const totalJobs = allQueues.reduce((sum, q) => sum + q.totalJobs, 0);
    const completedJobs = allQueues.reduce((sum, q) => sum + q.totalCompleted, 0);
    const failedJobs = allQueues.reduce((sum, q) => sum + q.totalFailed, 0);
    const activeJobs = allQueues.reduce((sum, q) => sum + q.processing.size, 0);

    const avgExecutionTime =
      allQueues.length > 0;
        ? allQueues.reduce((sum, q) => sum + q.averageExecutionTime, 0) / allQueues.length
        : 0;

    const successRate = totalJobs > 0 ? completedJobs / totalJobs : 0;
    const throughput = 0; // Would need time-based calculation

    const resourceUtil = this.getResourceUtilization();

    return {
      totalJobs,
      completedJobs,
      failedJobs,
      activeJobs,
      avgExecutionTime,
      successRate,
      throughput,
      resourceUtilization: resourceUtil,
      errorReduction: {
        totalErrors: 0, // Would need tracking
        errorsFixed: 0,
        reductionRate: 0
      },
      qualityMetrics: {
        buildStability: 0.85,
        testStability: 0.9,
        safetyScore: 0.8
      }
    } as ProcessingResult;
  }

  getOptimizations(): BatchOptimization[] {
    return Array.from(this.optimizations.values());
  }

  updateOptimizationParameters(optimizationId: string, parameters: Record<string, number>): void {
    const optimization = this.optimizations.get(optimizationId);
    if (optimization) {
      optimization.parameters = { ...optimization.parameters, ...parameters };
      optimization.adaptations++;
      this.persistData();
    }
  }

  resetOptimizations(): void {
    this.initializeOptimizations();
    this.persistData();
  }

  getStatus(): {
    isProcessing: boolean;
    queuesCount: number;
    optimizationsCount: number;
    activeJobs: number;
  } {
    const activeJobs = Array.from(this.queues.values()).reduce(;
      (sum, q) => sum + q.processing.size,
      0,
    );

    return {
      isProcessing: this.isProcessing,
      queuesCount: this.queues.size,
      optimizationsCount: this.optimizations.size,
      activeJobs
    };
  }
}

// ========== SINGLETON INSTANCE ==========;

export const _intelligentBatchProcessor = new IntelligentBatchProcessor();

// ========== EXPORT FACTORY ==========;

export const _createBatchProcessor = () => new IntelligentBatchProcessor();
